{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from IPython.display import clear_output\n!pip install -qU --upgrade pip\n!pip install -qU scikit-learn\n!pip install -qU wandb\n\nclear_output()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" !pip install -q /lib/wheels/tensorflow-2.9.1-cp38-cp38-linux_x86_64.whl\n# !pip install -qU /kaggle/input/whl-files/tensorflow-2.9.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n!pip install -q tensorflow-addons==0.18.0\n!pip install -q tensorflow-probability==0.17.0\n\n!pip install -q opencv-python-headless\n!pip install -q seaborn\n!pip install -q plotly","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -qU pydot\n!pip install -qU graphviz","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Basic python libraries\n%config Completer.use_jedi = False\nimport os, re, math, random, shutil, warnings, gc\nimport glob\nimport numpy as np, pandas as pd\nfrom IPython import display as ipd\nfrom tqdm import tqdm\n\n#Classical Ml tools\nimport sklearn\nfrom sklearn.model_selection import StratifiedGroupKFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.model_selection import train_test_split\n\n#OpenCV Library\nimport cv2\n\n#Plotting tools \nfrom matplotlib.ticker import StrMethodFormatter\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nimport matplotlib.pyplot as plt\nimport plotly.graph_objects as go\nimport plotly.express as px\nimport plotly.offline as py\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\n\n#Tensorflow and keras tools\nimport tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow.keras.backend as K\nfrom keras.models import Sequential,load_model,Model\nfrom keras.layers import Conv2D,MaxPooling2D,Dense,Dropout,BatchNormalization,Flatten,Input\nfrom keras import layers\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.python.client import device_lib\nfrom tensorflow.keras.layers.experimental.preprocessing import Rescaling\nfrom tensorflow.keras.applications import EfficientNetB3\nfrom keras.callbacks import EarlyStopping\n\nfrom kaggle_datasets import KaggleDatasets\nfrom kaggle_secrets import UserSecretsClient\n\n#Logging tools\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # to avoid too many logging messages\npd.options.mode.chained_assignment = None\ntf.get_logger().setLevel('ERROR')\npy.init_notebook_mode(connected=True)","metadata":{"cellView":"form","id":"tuOe1ymfHZPu","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('np:', np.__version__)\nprint('pd:', pd.__version__)\nprint('sklearn:', sklearn.__version__)\nprint('tf:',tf.__version__)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"devices = ['TPU', 'GPU']\nimg_size = [(1024,512), (512,256)]\n# img_size = [(1024,512), (224,224)]\nimg_ext = ['png']\n\nclass Config:\n    \n    def __init__(self):\n        \n        self.competition   = 'rsna-bcd' \n        self._wandb_kernel = 'Gebreyowhans'\n        \n        self.debug = True\n#         self.model_name = 'EfficientNetV1B3'\n        \n        self.device=devices[0]\n        self.seed=150\n        \n        self.path='/kaggle/input/rsna-bcd-converted-dicom-images/'\n        self.train_path= self.path+'train_images'\n        self.train_path = self.path + 'train_images/'\n        self.train_csv = self.path + 'train.csv'\n        self.weights = \"/kaggle/input/efficientnetb3-notop/efficientnetb3_notop.h5\"\n        \n        self.output_path='/kaggle/working/'\n        #number of folds for data-split\n        self.folds = 5\n        # which folds to train\n        self.train_folds = [0, 1, 2]\n        \n        self.oversampling = True\n        self.oversampling_factor = 10\n        self.threshold = 0.6\n        \n        #Model Parameters\n        self.batch_size=32\n        self.epochs=10\n        self.dropout=0.07\n        self.optimizer='adam'\n        self.loss='binary_crossentropy'\n        self.patience=5\n        self.img_size = img_size[1]\n        self.img_ext = img_ext[0] \n        \n        # ======Augumentation parameters====\n        # pixel-augment\n        self.sat  = [0.7, 1.3]\n        self.cont = [1,2]\n        self.bri  = 0.15\n        self.hue  = 0.05\n\n    \n\nconfig=Config()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seeding(seed):\n#     os.environ['PYTHONHASHSEED'] = str(seed)\n#     os.environ['TF_DETERMINISTIC_OPS'] = str(seed)\n#     os.environ['TF_CUDNN_DETERMINISTIC'] = str(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    random.seed(seed)\n    \n    print(\"Seeding done\")\n    \nseeding(config.seed)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if config.device == 'TPU':\n    \n    tpu = 'local' if config.device=='TPU' else None\n    print('Connecting to TPU...')\n    try:\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect(tpu=tpu)\n    except ValueError:\n        raise BaseException('ERROR: Not connected to a TPU runtime; please try executing it again or turnon your TPU VM v3-8 in your accelrator section of this note book !')\n    \n    policy =tf.keras.mixed_precision.Policy('float32') \n    tf.keras.mixed_precision.set_global_policy(policy)\n    \n    tf.config.set_soft_device_placement(True)\n    #strategy = tf.distribute.experimental.TPUStrategy(tpu)\n    strategy = tf.distribute.TPUStrategy(tpu)\n    \n    # TPU has to access the dataset from Google Cloud storage(GCS), so we have to set our path to GCS path\n    config.path = KaggleDatasets().get_gcs_path(config.path.split('/')[3])\n    config.train_path = config.path + '/' + 'train_images/'\n    \n    # get number of TPU cores connect at a runtime\n    config.num_devices = strategy.num_replicas_in_sync\n    \n    # batch size of for the TPU\n    config.batch_size = config.batch_size * config.num_devices\n    print(\"Batch size for TPU :\",config.batch_size)\n    print(f'Running on {config.num_devices} TPU devices')\n\n\nif config.device == 'GPU':\n    \n    #Number of GPU core connected\n    num_devices = len(tf.config.list_physical_devices('GPU'))\n    if num_devices > 1:\n        config.num_devices = num_devices\n        strategy = tf.distribute.MirroredStrategy()\n        config.batch_size = config.batch_size * config.num_devices\n        print(f'Running on {num_devices} GPU devices')\n        print(\"Batch size for multi core GPU :\",config.batch_size )\n        \n    elif num_devices == 1:\n        strategy = tf.distribute.get_strategy()\n        print(f'Running on {num_devices} GPU device')\n        \n    else:\n        strategy = tf.distribute.get_strategy()\n        config.device = 'CPU'\n        print(f'Running on CPU')\n    \n    tf.config.optimizer.set_jit(True)\n    \n    if config.device == 'TPU':\n        tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n    else:\n        tf.keras.mixed_precision.set_global_policy(policy=\"float32\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(config.train_csv)\n\nif config.debug:\n    train_df = train_df.sample(1000).reset_index(drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['image_path'] = config.train_path + train_df['patient_id'].astype(str) + '/' + train_df['image_id'].astype(str) + '.png'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.io.gfile.exists(train_df.image_path.iloc[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 9.Handle missing values ","metadata":{}},{"cell_type":"code","source":"def filter_missing_Features(df):\n    total_missing_data = [df[col].isnull().sum() for col in df.columns]\n    percentage_of_missing = [df[col].isnull().mean() for col in df.columns]\n    result = pd.DataFrame(zip(total_missing_data, percentage_of_missing), columns=['total_missing_data', 'percentage_of_missing'], index=df.columns)\n    result = result.sort_values('total_missing_data', ascending=False)\n    return result","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filter_missing_Features(train_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* BIRADS Columun have almost half missing and we don't know how to fill it so we decided better to remove this feature\n* The Age Columun also have very few missing values and we decided to fill these missing with average age value of the others\n\n* Density Columun have also almost half of missing data and we decided to fill it with other category labeld 'E'","metadata":{}},{"cell_type":"code","source":"train_df = train_df.drop(['BIRADS'], axis=1)\ntrain_df['age'] = train_df['age'].fillna(train_df['age'].mean())\ntrain_df['density'] = train_df['density'].fillna('E')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filter_missing_Features(train_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 10. Fix Data Types ","metadata":{}},{"cell_type":"code","source":"train_df['laterality'] = train_df['laterality'].astype('category')\ntrain_df['view'] = train_df['view'].astype('category')\ntrain_df['age'] = train_df['age'].astype('int64')\ntrain_df['density'] = train_df['density'].astype('category')\ntrain_df['image_path'] = train_df['image_path'].astype('string')\ntrain_df['cancer'] = train_df['cancer'].astype('float32')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 11. Numerical Categorization","metadata":{}},{"cell_type":"code","source":"train_df[\"age_bin\"] = pd.cut(train_df['age'].values.reshape(-1), bins=5, labels=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 12. Generate dummy variables ","metadata":{}},{"cell_type":"code","source":"cat_cols = ['laterality', 'view', 'density', 'difficult_negative_case']\ntrain_df = pd.get_dummies(train_df, columns=cat_cols)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[\"laterality_L\"] = train_df[\"laterality_L\"].astype(int)\ntrain_df[\"laterality_R\"] = train_df[\"laterality_R\"].astype(int)\ntrain_df[\"view_CC\"] = train_df[\"view_CC\"].astype(int)\ntrain_df[\"view_MLO\"] = train_df[\"view_MLO\"].astype(int)\ntrain_df[\"density_A\"] = train_df[\"density_A\"].astype(int)\ntrain_df[\"density_B\"] = train_df[\"density_B\"].astype(int)\ntrain_df[\"density_C\"] = train_df[\"density_C\"].astype(int)\ntrain_df[\"density_D\"] = train_df[\"density_D\"].astype(int)\ntrain_df[\"density_E\"] = train_df[\"density_E\"].astype(int)\ntrain_df[\"difficult_negative_case_False\"] = train_df[\"difficult_negative_case_False\"].astype(int)\ntrain_df[\"difficult_negative_case_True\"] = train_df[\"difficult_negative_case_True\"].astype(int)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 13. Stratified K-Fold Cross Validation \n\n* Stratified k-fold cross-validation is the same as just k-fold cross-validation, but Stratified k-fold  cross-validation, it does stratified sampling instead of random sampling. \n\n* This is particularly useful when dealing with imbalanced datasets, where one class or outcome variable is much more prevalent than the others.\n* Without stratification, a standard K-Fold Cross Validation could lead to some folds containing little or no instances of the minority class, which would bias the evaluation of the model's performance.\n* So since our dataset is highly imbalanced we decided to use this kind of cros validatio.","metadata":{}},{"cell_type":"code","source":"train_df.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stratified_columns = train_df.columns[~train_df.columns.isin(['patient_id', 'image_id', \n                                                              'image_path', 'target', \n                                                              'site_id', 'width', 'height', \n                                                              'age', 'invasive', \n                                                              'implant', 'machine_id'])]\n\ntrain_df['stratify'] = ''\nfor col in stratified_columns:\n    train_df['stratify'] += train_df[col].astype(str)\n     \n\ntrain_df['stratify'] = train_df['stratify'].astype('string')\n\nk_fold = StratifiedGroupKFold(n_splits=config.folds, shuffle=True, random_state=config.seed)\n\n\nfor fold, (train_idx, val_idx) in enumerate(k_fold.split(train_df, train_df['stratify'], train_df['patient_id'])):\n    train_df.loc[val_idx, 'fold'] = fold\n\ntrain_df['fold'] = train_df['fold'].astype('int32')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_df.groupby(['fold', \"cancer\"]).size())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# reshape the data into a pivot table\ncounts = train_df.groupby(['fold', 'cancer']).size().unstack()\n\n# plot the pivot table as a bar graph\ncounts.plot(kind='bar')\nplt.xlabel('Fold')\nplt.ylabel('Count')\nplt.title('Counts of samples by fold and cancer')\nplt.legend(['No cancer', 'Cancer'])\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 14. Data Pipeline","metadata":{}},{"cell_type":"markdown","source":"**14.1 Decode images**\n * **tf.image.decode_png()** and **tf.image.decode_jpeg** are TensorFlow functions that decodes a PNG-encoded   image into a tensor of type uint8.\n \n * These functions takes the following arguments: \n     * **image**: A string tensor containing a PNG or jpeg -encoded image.\n     * **channels**: An optional integer specifying the number of color channels in the decoded image. By  default, this is set to 3,\n     \n\n* The function returns a **uint8** tensor representing the decoded image with the shape of (height, width, channels) \n \n","metadata":{}},{"cell_type":"code","source":"def decode_image(label=True, img_size=config.img_size, ext=config.img_ext):\n    \n    def _decode_image(Input_Image, label=None):\n        image = tf.io.read_file(Input_Image['input_image'])\n        \n        if ext == 'png':\n            ## PNG-encoded image into a tensor of type uint8.\n            image = tf.image.decode_png(image, channels=3)\n        elif ext in ['jpg', 'jpeg']:\n            ## jpeg-encoded image into a tensor of type uint8.\n            image = tf.image.decode_jpeg(image, channels=3)\n        else:\n            raise ValueError(\"Image extension not supported\")\n        \n        ## explicit size needed for TPU\n        image = tf.image.resize(image, img_size)\n        ## convert image to floats in [0, 1] range\n        image = tf.cast(image, tf.float32) / 255.0\n        \n        Input_Image['input_image'] = image\n        \n        if label is None:\n            return Input_Image\n        else:\n            return Input_Image, label\n    \n    if label:\n        return _decode_image\n    else:\n        return lambda x: _decode_image(x, None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*** 14.2 Data augumentation**\n* Using Augmentations to reduce overfitting and make model more robust by :\n * 1. random_flip_left_right for applying position transforamtion\n * 2. perofrming some random_hue,random_saturation,random_contrast,random_brightness for pixel transforamtion","metadata":{}},{"cell_type":"code","source":"def data_augment(label=True):\n    def _augment(Input_Image, label=None):\n        image = Input_Image['input_image']\n        #position transforamtion\n        image = tf.image.random_flip_left_right(image)\n        # pixel-augment\n        image = tf.image.random_hue(image, config.hue)\n        image = tf.image.random_saturation(image,config.sat[0], config.sat[1])\n        image = tf.image.random_contrast(image,config.cont[0], config.cont[1])\n        image = tf.image.random_brightness(image,config.bri)\n        Input_Image['input_image'] = image\n        if label is not None:\n            return Input_Image, label\n        else:\n            return Input_Image\n\n    if label:\n        return _augment\n    else:\n        return lambda x: _augment(x, None)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_dataset(df, input_features, image_size=config.img_size, batch_size=config.batch_size, \n                  label=True, shuffle=True, augment=False, repeat=False, cache=False, ext=config.img_ext):\n    \n    decode = decode_image(label, img_size=image_size, ext=ext)\n    input_data = {'input_image': df['image_path'].values, 'input_features': df[input_features].values}\n    \n    if label:\n        label_data = df['cancer'].apply(lambda x: int(x)).values\n        dataset = tf.data.Dataset.from_tensor_slices((input_data, label_data))\n    else:\n        dataset = tf.data.Dataset.from_tensor_slices(input_data)\n        \n    dataset = dataset.map(decode, num_parallel_calls=tf.data.AUTOTUNE)\n    \n    if augment:\n        dataset = dataset.map(data_augment(label), num_parallel_calls=tf.data.AUTOTUNE)\n    if shuffle:\n        dataset = dataset.shuffle(batch_size, reshuffle_each_iteration=True)\n    if repeat:\n        dataset = dataset.repeat()\n    if cache:\n        dataset = dataset.cache()\n        \n    dataset = dataset.batch(batch_size, drop_remainder=shuffle)\n    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n    return dataset\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 15. Input Features","metadata":{}},{"cell_type":"code","source":"input_features = train_df.columns.difference(['patient_id', 'image_id', 'site_id', 'machine_id',\n                                              'width', 'height', 'cancer', 'age', \n                                              'stratify', 'image_path', 'fold'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Input_features_chagned_to_tensor  = build_dataset(train_df, input_features, batch_size=config.batch_size, label=True, \n                                     shuffle=False, augment=True, repeat=False, cache=False, ext=config.img_ext)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for item in Input_features_chagned_to_tensor.take(1):\n#     print(item)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 16. Some augumented and non augumented images","metadata":{}},{"cell_type":"code","source":"def show_images(dataset,  title=\"\", rows=1, cols=5, figsize=(20, 8)):\n    fig = plt.figure(figsize=figsize)\n    grid = ImageGrid(fig, 111, nrows_ncols=(rows, cols), axes_pad=0.2)\n    for i, (images, labels) in enumerate(dataset.take(1)):\n        for j in range(rows*cols):\n            grid[j].imshow(images['input_image'][j].numpy())\n            grid[j].set_title(f\"Label: {labels[j].numpy()}\")\n    plt.suptitle(title)\n    plt.show()\n\n\nsample_with_augument = build_dataset(train_df, input_features, batch_size=config.batch_size, label=True, \n                                     shuffle=False, augment=True, repeat=False, cache=False, ext=config.img_ext)\n\nsample_without_augument = build_dataset(train_df, input_features, batch_size=config.batch_size, label=True, \n                                        shuffle=False, augment=False, repeat=False, cache=False, ext=config.img_ext)\n\n\nshow_images(sample_without_augument, title=\"Without Augumentation\")\nshow_images(sample_with_augument, title=\"With Augumentation\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 17. Normalization","metadata":{}},{"cell_type":"code","source":"train_df[input_features] = (train_df[input_features] - train_df[input_features].mean()) / train_df[input_features].std()\ntrain_df[input_features] = train_df[input_features].astype('float32')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[input_features]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 18. Evaluation Metrics","metadata":{}},{"cell_type":"code","source":"def p_f1(y_true, y_pred):\n    y_true = tf.cast(y_true, tf.float32)\n    y_pred = tf.cast(y_pred, tf.float32)\n    \n    tp = tf.reduce_sum(y_true * y_pred)\n    tn = tf.reduce_sum((1 - y_true) * (1 - y_pred))\n    fp = tf.reduce_sum((1 - y_true) * y_pred)\n    fn = tf.reduce_sum(y_true * (1 - y_pred))\n    \n    p = tp / (tp + fp + tf.keras.backend.epsilon())\n    r = tp / (tp + fn + tf.keras.backend.epsilon())\n    \n    f1 = 2 * p * r / (p + r + tf.keras.backend.epsilon())\n    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n\n    return tf.reduce_mean(f1)\n\ndef p_f1_np(y_true, y_pred):\n    y_true = y_true.astype(np.float32)\n    y_pred = y_pred.astype(np.float32)\n    \n    tp = np.sum(y_true * y_pred)\n    tn = np.sum((1 - y_true) * (1 - y_pred))\n    fp = np.sum((1 - y_true) * y_pred)\n    fn = np.sum(y_true * (1 - y_pred))\n    \n    p = tp / (tp + fp + np.finfo(np.float32).eps)\n    r = tp / (tp + fn + np.finfo(np.float32).eps)\n    \n    f1 = 2 * p * r / (p + r + np.finfo(np.float32).eps)\n    f1 = np.where(np.isnan(f1), np.zeros_like(f1), f1)\n\n    return np.mean(f1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 19.Model Building","metadata":{}},{"cell_type":"code","source":"def build_model(input_features, \n                loss=config.loss, \n                dropout=config.dropout, \n                optimizer=config.optimizer, \n                img_size=config.img_size):\n    with strategy.scope():\n#         input_image = tf.keras.layers.Input(shape=(*img_size,3), name='input_image')\n        input_image = tf.keras.Input((*img_size, 3), name='input_image')\n#         input_features = tf.keras.layers.Input(shape=[len(input_features)], name='input_features')\n        \n        efficientNetBase_model = tf.keras.applications.EfficientNetB4(input_shape=(*img_size,3),\n                                                 include_top=False, \n                                                 drop_connect_rate=0.3,\n                                                 weights='imagenet')(input_image)\n        \n        x = tf.keras.layers.GlobalAveragePooling2D()(efficientNetBase_model)\n        x = tf.keras.layers.Flatten()(x)\n#         _output = tf.keras.layers.Dropout(dropout)(x)\n        _output = tf.keras.layers.Dense(32, activation=\"relu\")(_output)\n#         _output = tf.keras.layers.BatchNormalization()(_output)\n#         _output = tf.keras.layers.Dropout(dropout)(_output)\n#         _output = tf.keras.layers.Concatenate()([_output, input_features])\n        _output = tf.keras.layers.Dense(1, activation='sigmoid')(_output)\n                \n#       \n        model = tf.keras.Model(inputs=[input_image], outputs=_output)\n#         model = tf.keras.Model(inputs=[input_image, input_features], outputs=_output)\n        model.compile(optimizer=optimizer,\n              loss=loss,\n              metrics=['accuracy', \n                       p_f1])\n\n        return model\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 20. Model Summary","metadata":{}},{"cell_type":"code","source":"model = build_model(input_features,config.loss,config.dropout,config.optimizer,config.img_size)\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 21. Ploting the model ","metadata":{}},{"cell_type":"code","source":"tf.keras.utils.plot_model(model, show_shapes=True, dpi=64)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 22. Defining Model Compilation","metadata":{}},{"cell_type":"code","source":"\n##tf.keras.metrics.AUC(name='auc')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def lr_scheduler(batch_size=config.batch_size, plot=False):\n    \n    lr_start   = 0.000001\n    lr_max     = 0.00000105 * batch_size\n    lr_min     = 0.000001\n    lr_ramp_ep = 5\n    lr_sus_ep  = 0\n    lr_decay   = 0.8\n    \n    def lr_fn(epoch):\n        if epoch < lr_ramp_ep:\n            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n        elif epoch < lr_ramp_ep + lr_sus_ep:\n            lr = lr_max\n        else:\n            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n        return lr\n    \n    if plot:\n        plt.figure(figsize=(10, 5))\n        rng = [i for i in range(config.epochs+1)]\n        y = [lr_fn(x) for x in rng]\n        fig = go.Figure()\n        fig.add_trace(go.Scatter(x=rng, y=y, mode='lines+markers', name='lr'))\n        fig.update_yaxes(tickformat=\".5f\")\n        fig.update_layout(title='Learning Rate Schedule', xaxis_title='Epoch', yaxis_title='Learning Rate')\n        fig.show()\n\n    \n    lr_callback = tf.keras.callbacks.LearningRateScheduler(lr_fn, verbose=False)\n    return lr_callback\n\n\n_ = lr_scheduler(batch_size=config.batch_size, plot=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 23 Defining callback function saving models to output directory","metadata":{}},{"cell_type":"code","source":"# Create directory model weightes saving\nsave_model_dir = os.path.join(config.output_path,'models')\nos.makedirs(os.path.dirname(save_model_dir), exist_ok=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_callbacks(batch_size, fold, patience=config.patience):\n    early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", \n                                             mode=\"min\",\n                                             patience=patience,\n                                             restore_best_weights=True)\n    \n    best_model = tf.keras.callbacks.ModelCheckpoint(f'{save_model_dir}/model_{fold}.h5', \n                                                    monitor='val_p_f1',\n                                                    mode='max', \n                                                    save_freq='epoch', \n                                                    save_best_only=True, \n                                                    save_weights_only=False,\n                                                    verbose=1)\n    callbacks_list = [early_stop, \n                      best_model,\n                      lr_scheduler(batch_size)\n                     ]\n    return callbacks_list","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 24. Training ","metadata":{}},{"cell_type":"code","source":"results = {}\n\nfor fold in range(config.folds):\n    \n    if fold in config.train_folds:\n        continue\n    \n    \n    \n    print(f'\\n- Fold [{fold}] as validation set, and folds {[i for i in range(config.folds) if i != fold]} as training set\\n')\n    \n    train = train_df.query(\"fold != @fold\")\n    validation = train_df.query(\"fold == @fold\")\n    \n    print(\"number of examples in training : \",len(train))\n    print(\"number of examples in validation : \",len(validation))\n\n    if config.oversampling:\n        \n        numberofCancers=train.query('cancer == 1')\n        numberofNonCancer=train.query('cancer == 0')\n        \n        print(\"numberofCancers :\",len(numberofCancers))\n        print(\"numberofNonCancer :\",len(numberofNonCancer))\n        \n        positive = train.query('cancer == 1').sample(frac=config.oversampling_factor, replace=True, \n                                                     random_state=config.seed)\n        negative = train.query('cancer == 0')\n        train = pd.concat([positive, negative], axis=0).reset_index(drop=True)\n        print(\"number of examples in after upsampling : \",len(train))\n    \n    train_dataset = build_dataset(train, input_features, batch_size=config.batch_size, \n                                  shuffle=True, augment=True, repeat=False, cache=True)\n          \n    val_dataset = build_dataset(validation, input_features, batch_size=config.batch_size, \n                                shuffle=False, augment=False, repeat=False, cache=True)\n    \n    class_weight = compute_class_weight(class_weight='balanced',\n                                        classes=train[\"cancer\"].unique(),\n                                        y=train[\"cancer\"].values)\n    \n    model = build_model(input_features)\n    \n    history = model.fit(train_dataset, \n                        validation_data = val_dataset, \n                        epochs = config.epochs,\n                        callbacks = get_callbacks(config.batch_size, fold),\n                        class_weight = dict(zip(train[\"cancer\"].unique(), class_weight)),\n                        steps_per_epoch = len(train) // config.batch_size)\n    \n    print('========================performing out-of-fold predictions ============================================')\n    print('======== Loading saved model ========================')\n    model.load_weights(f'{save_model_dir}/model_{fold}.h5')\n\n    print('================Predicting OOF validation set ========================')\n    b_val_dataset = build_dataset(validation, input_features,\n                                  batch_size=config.batch_size, \n                                  shuffle=False, augment=True, repeat=False, cache=True)\n    \n    #Remove singleton dimensionality with squeeze function\n    validation['pred'] = np.squeeze(model.predict(b_val_dataset, verbose=1).astype('float32'))\n    validation['pred'] = (validation['pred'] > config.threshold).astype(int)\n\n\n\n    print(' ================Compute metrics========================')\n    pf = p_f1_np(validation['cancer'], validation['pred'])\n    auc = roc_auc_score(validation['cancer'], validation['pred'])\n    accuracy = accuracy_score(validation['cancer'], validation['pred'])\n\n    \n    results[fold] = {'p_f1': pf,'accuracy': accuracy}\n    print(f'- P-F1: {pf}, Accuracy: {accuracy}\\n')\n   \n    \n    del model\n    gc.collect()\n    tf.keras.backend.clear_session()\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 25. Plot of accuracy and loss functions","metadata":{}},{"cell_type":"code","source":"def plot_evaluation_metrics(history):\n    accuracy = history.history[\"accuracy\"]\n    val_accuracy = history.history[\"val_accuracy\"]\n    loss = history.history[\"loss\"]\n    val_loss = history.history[\"val_loss\"]\n    epochs = range(1, len(accuracy) + 1)\n    plt.plot(epochs, accuracy, \"r\", label=\"Training accuracy\")\n    plt.plot(epochs, val_accuracy, \"g\", label=\"Validation accuracy\")\n    \n    plt.title(\"Training and validation accuracy\")\n    plt.legend()\n    plt.figure()\n    plt.plot(epochs, loss, \"r\", label=\"Training loss\")\n    plt.plot(epochs, val_loss, \"g\", label=\"Validation loss\")\n    plt.title(\"Training and validation loss\")\n    plt.legend()\n    plt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_evaluation_metrics(history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.backend.clear_session()\n# experiment.end()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}